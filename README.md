# MVCNet

This repository provides the official implementation of [**MVCNet: Multi-View Contrastive Network for Motor Imagery Classification**](https://arxiv.org/abs/2502.17482). The code of baseline models is in our another respository [**DBConformer**](https://github.com/wzwvv/DBConformer), serving as a benchmark codebase for EEG decoding models.

MVCNet is a dual-branch framework that integrates multi-view data augmentation, CNNâ€“Transformer parallel modeling, and supervised contrastive learning to improve representation learning and decoding generalizability of EEG-based MI Classification.

<img width="916" alt="image" src="https://github.com/user-attachments/assets/2cf32c83-5fc5-422c-b731-51243483feff" />



## ğŸ“ Project Structure

The codebase is organized as follows:

```
MVCNet/
â”‚
â”œâ”€â”€ MVCNet_CO.py        # Main script for the Chronological Order (CO) scenario
â”œâ”€â”€ MVCNet_CV.py        # Main script for the Cross-Validation (CV) scenario
â”œâ”€â”€ MVCNet_LOSO.py      # Main script for the Leave-One-Subject-Out (LOSO) scenario
â”‚
â”œâ”€â”€ models/             # Implementations of MVCNet and baseline models
â”‚   â”œâ”€â”€ IFNet.py
â”‚   â”œâ”€â”€ Conformer.py
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ data/             # datasets
â”‚   â”œâ”€â”€ BNCI2014001
â”‚   â”œâ”€â”€ Zhou2016
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ utils/              # Utility functions
â”‚   â”œâ”€â”€ data_augment.py     # Data augmentation (e.g., time, frequency, spatial)
â”‚   â”œâ”€â”€ contrastive_loss.py # Contrastive loss definitions
â”‚   â”œâ”€â”€ network.py          # encoder, decoder, etc
â”‚   â””â”€â”€ ...
â”‚
â””â”€â”€ README.md
```


## ğŸ§ª Experimental Scenarios

MVCNet supports three standard MI decoding paradigms:

- **CO (Chronological Order):** Within-subject, time-based data split
- **CV (Cross-Validation):** Within-subject, stratified 5-fold validation. The data partitions were structured chronologically while maintaining class-balance, following FBCNet.
- **LOSO (Leave-One-Subject-Out):** Cross-subject generalization evaluation

## ğŸ“Š Comparison with Baseline Models

Classification Accuracy (%) Â± Std on Five MI Datasets under CO setting:

| Dataset        | EEGNet        | SCNN          | DCNN          | FBCNet        | ADFCNN        | EEGConformer  | IFNet         | **MVCNet (Ours)** |
|----------------|---------------|---------------|---------------|---------------|---------------|---------------|---------------|-------------------|
| BNCI2014001    | 69.05 Â± 1.00  | 73.57 Â± 2.36  | 59.29 Â± 1.64  | 68.97 Â± 1.26  | 73.73 Â± 2.26  | 78.57 Â± 0.66  | 77.94 Â± 0.93  | **83.17 Â± 0.74**  |
| Zhou2016       | 80.13 Â± 3.35  | 75.03 Â± 6.15  | 78.03 Â± 2.37  | 63.33 Â± 2.29  | 71.42 Â± 1.95  | 73.87 Â± 4.51  | 81.70 Â± 2.08  | **84.11 Â± 2.68**  |
| Blankertz2007  | 78.79 Â± 2.78  | 76.71 Â± 2.09  | 70.00 Â± 4.12  | 75.93 Â± 1.31  | 76.07 Â± 1.41  | 82.29 Â± 2.62  | 84.00 Â± 0.57  | **87.07 Â± 0.52**  |
| BNCI2014002    | 66.07 Â± 2.76  | 79.07 Â± 1.96  | 64.07 Â± 2.70  | 69.50 Â± 0.95  | 73.00 Â± 1.95  | 76.21 Â± 1.46  | 78.29 Â± 1.68  | **81.29 Â± 2.31**  |
| BNCI2015001    | 75.58 Â± 1.69  | 83.71 Â± 1.34  | 71.08 Â± 1.82  | 74.92 Â± 0.97  | 78.75 Â± 0.62  | 82.63 Â± 0.54  | 83.83 Â± 0.90  | **85.67 Â± 0.55**  |
| Average    | 73.92         | 77.62         | 68.49         | 70.53         | 74.59         | 78.71         | 81.15         | **84.26**         |

## ğŸ”¬ Ablation Study

Classification Accuracy (%) Â± Std on Five MI Datasets under CO Setting:

| Dataset        | MVCNet         | MVCNet (cvc)   | MVCNet (cmc)   |
|----------------|----------------|----------------|----------------|
| BNCI2014001    | 83.17 Â± 0.74   | 82.70 Â± 1.05   | 82.46 Â± 0.46   |
| Zhou2016       | 84.11 Â± 2.68   | 83.18 Â± 3.07   | 82.22 Â± 2.61   |
| Blankertz2007  | 87.07 Â± 0.52   | 85.71 Â± 1.30   | 86.21 Â± 1.42   |
| BNCI2014002    | 81.29 Â± 2.31   | 81.29 Â± 1.82   | 81.21 Â± 1.92   |
| BNCI2015001    | 85.67 Â± 0.55   | 85.67 Â± 0.08   | 85.42 Â± 0.32   |
|   Average      |   84.26        | 83.71          | 83.51          |

- MVCNet: using both CVC and CMC contrastive modules.
- MVCNet (cvc): only using the cross-view contrasting module.
- MVCNet (cmc): only using the cross-model contrasting module.

## ğŸ“‚ Dataset

For reproducibility, the preprocessed EEG dataset **BNCI2014001** can be accessed at (put X.npy into /data/BNCI2014001/):

```
ğŸ”— https://pan.baidu.com/s/19osNsaDnNliQTXxiK3ncOA  (æå–ç : pdtg)
```

All datasets can be downloaded from [the Mother Of All BCI Benchmarks (MOABB)](https://moabb.neurotechx.com)

---

## ğŸ’¡ Citation

If you find this work helpful, please consider citing our paper:

```
@article{wang2025mvcnet,
      title={MVCNet: Multi-View Contrastive Network for Motor Imagery Classification}, 
      author={Ziwei Wang and Siyang Li and Xiaoqing Chen and Wei Li and Dongrui Wu},
      journal={arXiv preprint arXiv:2502.17482},
      year={2025}
}
```

## ğŸ™Œ Acknowledgments

Special thanks to Jiaheng for providing the source code of [IFNet](https://github.com/Jiaheng-Wang/IFNet), which served as a valuable foundation for our implementation.

We appreciate your interest and patience. Feel free to raise issues or pull requests for questions or improvements.
